{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmi-keerthi/MLPractice/blob/main/Classification%20of%20fashion%20clothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3n9jnJ9R9xm"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQGnX6WSBAc"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBP8TMYXSG4n"
      },
      "source": [
        "To improve the classification performance of the Fashion MNIST images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KComERdDSBsl"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* Understand the Feature extraction\n",
        "* Know how PCA effects the classification accuracy\n",
        "* Train the classifier with PCA\n",
        "* Classify using MLP with different parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgIey_t0bCGL"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBiGVshpbFNe"
      },
      "source": [
        "### History\n",
        "The original MNIST dataset contains handwritten digits. People from AI/ML or Data Science community love this dataset. They use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset they would try on. As per popular belief, If the algorithm doesn’t work on MNIST, it won’t work at all. Well, if algorithm works on MNIST, it may still fail on other datasets.\n",
        "\n",
        "\n",
        "As per the original [paper](https://arxiv.org/abs/1708.07747) describing about Fashion-MNIST, It is a dataset recomposed from the product pictures of Zalando’s websites. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits.\n",
        "\n",
        "There are some good reasons for the challenges faced by MNIST dataset:\n",
        "\n",
        "* MNIST is too easy - Neural networks can achieve 99.7% on MNIST easily, and similarly, even classic ML algorithms can achieve 97%.\n",
        "\n",
        "* MNIST is overused - Almost everyone who has experience with deep learning has come across MNIST at least once.\n",
        "\n",
        "* MNIST cannot represent modern CV task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCTyBKLvbJst"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YW0bfzFbU4F"
      },
      "source": [
        "The dataset choosen for this experiment is Fashion-MNIST. The dataset is made up of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.\n",
        "\n",
        "**Labels / Classes**\n",
        "\n",
        "0 - T-shirt/top\n",
        "\n",
        "1 - Trouser\n",
        "\n",
        "2 - Pullover\n",
        "\n",
        "3 - Dress\n",
        "\n",
        "4 - Coat\n",
        "\n",
        "5 - Sandal\n",
        "\n",
        "6 - Shirt\n",
        "\n",
        "7 - Sneaker\n",
        "\n",
        "8 - Bag\n",
        "\n",
        "9 - Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf18DcPGbpZw"
      },
      "source": [
        "## Grading = 20 Marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5djNNQBbg10"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2001381\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"8885332495\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook=\"Sample\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Mini-Hackathon/fashion.zip\")\n",
        "    #ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/fashion-mnist_test.csv\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "\n",
        "def submit_notebook():\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getInclassSupport() and getOnlineSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Inclass_support,\n",
        "              \"feedback_online_mentor\" : Online_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "def getInclassSupport():\n",
        "  try:\n",
        "    if not Inclass_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Inclass_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Inclass support Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getOnlineSupport():\n",
        "  try:\n",
        "    if not Online_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Online_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Online support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAcmbHmu_Op3"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgc-dv8E_RZp"
      },
      "source": [
        "!unzip fashion.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3ksxwTIbz8X"
      },
      "source": [
        "### Importing Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvhymkVDbkbA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulkzHdBecQW2"
      },
      "source": [
        "# **Stage 1:** Classify with raw features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzZdum4YcpVn"
      },
      "source": [
        "### 3Marks -> Get the features and labels of Fashion MNIST train data\n",
        "\n",
        "1. Extract the features of the images\n",
        "\n",
        "   Hint: [Link](https://www.analyticsvidhya.com/blog/2019/08/3-techniques-extract-features-from-image-data-machine-learning-python/)\n",
        "\n",
        "2. Convert the features to numpy array\n",
        "\n",
        "3. Normalize the features\n",
        "\n",
        "3. Convert the categorical value to the numericals\n",
        "\n",
        "5. Plot the first 5 images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBzl3f-_WpfI"
      },
      "source": [
        "\n",
        "%cd /content/fashion/img/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwAijH0NcMu0"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# For extracting the pixel values of all the images\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import re\n",
        "\n",
        "def get_features_labels(path):\n",
        "  df = pd.read_csv(path)\n",
        "  Images = [i[i.find('/')+1:] for i in list(df['image'])]\n",
        "  categories = list(df['category'])\n",
        "  # For extracting the pixel values of all the image\n",
        "  !cd /content/fashion/img/\n",
        "  features = [imread(Images[i], as_gray=True).reshape(28*28) for i in range(0,len(Images))]\n",
        "  # For normalizing the features\n",
        "  features_normalized = preprocessing.normalize(features, norm='l2')\n",
        "  # For converting categorical variables to numeric\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  categories = le.fit_transform(categories)\n",
        "  return features_normalized,categories\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKr2I_96fo3s"
      },
      "source": [
        "path='/content/fashion/index_train.csv'\n",
        "features_normalized,categories = get_features_labels(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuNanDmQjgU2"
      },
      "source": [
        "### 3Marks -> Train the MLP classifier on raw features\n",
        "\n",
        "1. Split the data\n",
        "\n",
        "2. Train the MLP classifier with different parameters\n",
        "\n",
        "3. Get the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY7t4WW_3JQT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train = features_normalized\n",
        "y = categories\n",
        "\n",
        "def mlp(a, s, h, mi, lr, lri, rs):\n",
        "    clf = MLPClassifier(activation= a, solver= s, hidden_layer_sizes = h, max_iter = mi, learning_rate =lr, learning_rate_init=lri, random_state=rs,early_stopping= True)\n",
        "    return clf\n",
        "def accuracy(actual,predicted):\n",
        "    return accuracy_score(actual,predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3JJrwi9eBhW"
      },
      "source": [
        "activation = [\"logistic\"]\n",
        "solvers = [\"adam\"]\n",
        "hidden_layers = [(30,5)]\n",
        "max_i = [200]\n",
        "learning_r = ['adaptive']\n",
        "learning_rate_i = [0.001]\n",
        "random_state = [42]\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "models = []\n",
        "for i in range(1):\n",
        "    k1 = np.random.randint(0,len(activation))\n",
        "    k2 = np.random.randint(0,len(solvers))\n",
        "    k3 = np.random.randint(0,len(hidden_layers))\n",
        "    k4 = np.random.randint(0,len(max_i))\n",
        "    k5 = np.random.randint(0,len(learning_r))\n",
        "    k6 = np.random.randint(0,len(learning_rate_i))\n",
        "    k7 = np.random.randint(0,len(random_state))\n",
        "    print(\"\\nHyper-parameters = \\n activation = \", activation[k1], \"\\n solver = \", solvers[k2],\n",
        "          \"\\n hidden_layer_sizes = \", hidden_layers[k3], \"\\n max_iter = \", max_i[k4],\n",
        "          \"\\n learning_rate = \", learning_r[k5], \"\\n learning_rate_init = \", learning_rate_i[k6], \"\\n random_state = \", random_state[k7])\n",
        "    #calling the mlp function with random hyper paramters\n",
        "    clf = mlp(activation[k1],solvers[k2],hidden_layers[k3], max_i[k4], learning_r[k5], learning_rate_i[k6], random_state[k7])\n",
        "    #Fitting the data into model\n",
        "    clf.fit(X_train,y)\n",
        "    models.append(clf)\n",
        "    ## Predicting the values on trained model using train data\n",
        "    predTrain = clf.predict((X_train))\n",
        "    #Calculating the train accuracy\n",
        "    train_accuracy.append(accuracy(y,predTrain))\n",
        "    print(\"(train) accuracy = \",accuracy(y,predTrain))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5TrSwzPizYm"
      },
      "source": [
        "## **Stage 2:** Classify with PCA features\n",
        "\n",
        "Principal component analysis can be used to reduce the dimensions of an image and project back the data from the reduced space to reconstruct the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ_VccAJku9C"
      },
      "source": [
        "### 3Marks -> Apply PCA on normalized features with different components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl-GPXPXmZQV"
      },
      "source": [
        "from time import time\n",
        "from sklearn.decomposition import PCA\n",
        "import logging\n",
        "n_components = 350\n",
        "print(\"Extracting the top %d features from %d features\"\n",
        "      % (n_components, X_train.shape[0]))\n",
        "# Starting the timer\n",
        "t0 = time()\n",
        "# Trying to extract PCA features using PCA function from sklearn\n",
        "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
        "# Printing the time taken to extract the features\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "# Storing the eigen faces\n",
        "pca_features = pca.components_.reshape(n_components,784)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjOf0RVOqj5Q"
      },
      "source": [
        "# Transforming the data\n",
        "X_train_pca = pca.transform(X_train)\n",
        "print(\"done in %0.3fs\" % (time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGyUpZUXrONc"
      },
      "source": [
        "# Checking for the shape of the original data\n",
        "X_train.shape, X_train_pca.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tkBizxfw_B_"
      },
      "source": [
        "## Applying K-Folds cross-validator\n",
        "kf = KFold(n_splits=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DlBFqnTsLyX"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "activation = [\"relu\"]\n",
        "solvers = [\"adam\"]\n",
        "hidden_layers = [(50,45)]\n",
        "max_i = [500]\n",
        "learning_r = ['adaptive']\n",
        "learning_rate_i = [0.0005]\n",
        "random_state = [42]\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "models = []\n",
        "for i in range(1):\n",
        "    k1 = np.random.randint(0,len(activation))\n",
        "    k2 = np.random.randint(0,len(solvers))\n",
        "    k3 = np.random.randint(0,len(hidden_layers))\n",
        "    k4 = np.random.randint(0,len(max_i))\n",
        "    k5 = np.random.randint(0,len(learning_r))\n",
        "    k6 = np.random.randint(0,len(learning_rate_i))\n",
        "    k7 = np.random.randint(0,len(random_state))\n",
        "    print(\"\\nHyper-parameters = \\n activation = \", activation[k1], \"\\n solver = \", solvers[k2],\n",
        "          \"\\n hidden_layer_sizes = \", hidden_layers[k3], \"\\n max_iter = \", max_i[k4],\n",
        "          \"\\n learning_rate = \", learning_r[k5], \"\\n learning_rate_init = \", learning_rate_i[k6], \"\\n random_state = \", random_state[k7])\n",
        "    #calling the mlp function with random hyper paramters\n",
        "    clf = mlp(activation[k1],solvers[k2],hidden_layers[k3], max_i[k4], learning_r[k5], learning_rate_i[k6], random_state[k7])\n",
        "    tempTrain = 0\n",
        "    tempTest = 0\n",
        "    for nbrOfFolds,(train_index, test_index) in enumerate(kf.split(X_train_pca)):\n",
        "        ## Splitting the data into train and test\n",
        "        X_train, X_test = X_train_pca[train_index], X_train_pca[test_index]\n",
        "        Y_train, Y_test  = y[train_index], y[test_index]\n",
        "        #Fitting the data into model\n",
        "        clf.fit(X_train,Y_train)\n",
        "        ## Predicting the values on trained model using train data\n",
        "        predTrain = clf.predict((X_train))\n",
        "        #adding the accuracy\n",
        "        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n",
        "        ##predict the values on the fitted model using test data\n",
        "        predTest = clf.predict((X_test))\n",
        "        #adding the accuracy\n",
        "        tempTest = tempTest + accuracy(Y_test,predTest)\n",
        "        models.append(clf)\n",
        "    #Calculating the train accuracy\n",
        "    print(f'Number of folds is{nbrOfFolds+1}')\n",
        "    print(f'Number of folds is{nbrOfFolds+1}')\n",
        "    train_accuracy.append(tempTrain*1.0/(nbrOfFolds+1))\n",
        "    ##Calculating the test accuracy\n",
        "    test_accuracy.append(tempTest*1.0/(nbrOfFolds+1))\n",
        "    print(\"(train,test) accuracy = \",tempTrain*1.0/(nbrOfFolds+1), tempTest*1.0/(nbrOfFolds+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owiL24GKVulB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyx2aqwQVvHS"
      },
      "source": [
        "path='/content/fashion/index_test.csv'\n",
        "Test_features,Test_labels = get_features_labels(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IVkM6ryZ2wc"
      },
      "source": [
        "# YOUR CODE HERE for getting the features of the test data.\n",
        "Test_features =[] #Do not change the name as it is used for the mentors evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FaxSpIQJHMs"
      },
      "source": [
        "# YOUR CODE HERE for getting the numerical labels as defined in train data\n",
        "Test_labels=[] #Do not change the name as it is used for the mentors evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w75QzZ3oojC"
      },
      "source": [
        "# Give the model name\n",
        "X_test_pca = pca.transform(Test_features)\n",
        "predicted_values = clf.predict(X_test_pca)\n",
        "accuracy_score(predicted_values,Test_labels)\n",
        "print(accuracy_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score"
      ],
      "metadata": {
        "id": "WmriPMZHDyd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N-AZc_3yI0kt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}